import streamlit as st

def app():
    st.set_page_config(page_title="Information", page_icon="üßæ")

    st.markdown("""
# D·ª± ƒëo√°n gi√° nh√†

## M√¥ t·∫£

"D·ª± ƒëo√°n v·ªÅ gi√° nh√†", x√¢y d·ª±ng tr√™n Streamlit framework, ƒë∆∞·ª£c ph√°t tri·ªÉn b·∫±ng c√°ch s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu Kaggle 'House Prices - Advanced Regression Techniques'.

## D·ªØ li·ªáu
B·ªô d·ªØ li·ªáu (dataset) tham kh·∫£o t·∫°i [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques).

## M·ª•c ti√™u

M·ª•c ti√™u c·ªßa d·ª± √°n n√†y l√† d·ª± ƒëo√°n gi√° c·ªßa m·ªôt ng√¥i nh√† ·ªü Ames b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c thu·ªôc t√≠nh do b·ªô d·ªØ li·ªáu cung c·∫•p.

## Thu·ªôc t√≠nh

B·ªô d·ªØ li·ªáu ch·ª©a c√°c thu·ªôc t√≠nh sau:

* **OverallQual**: Ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ c·ªßa ng√¥i nh√†
* **GrLivArea**: Di·ªán t√≠ch sinh ho·∫°t tr√™n t·∫ßng (m·∫∑t ƒë·∫•t) feet vu√¥ng
* **GarageCars**: S·ªë l∆∞·ª£ng gara √¥ t√¥
* **TotalBsmtSF**: T·ªïng di·ªán t√≠ch th∆∞·ªõc vu√¥ng di·ªán t√≠ch t·∫ßng h·∫ßm
* **FullBath**: S·ªë l∆∞·ª£ng b·ªìn t·∫Øm
* **YearBuilt**: NƒÉm x√¢y nh√†
* **TotRmsAbvGrd**: T·ªïng s·ªë ph√≤ng tr√™n c·∫•p (kh√¥ng bao g·ªìm ph√≤ng t·∫Øm v√† t·ªß qu·∫ßn √°o)
* **Fireplaces**: S·ªë l∆∞·ª£ng l√≤ s∆∞·ªüi
* **BedroomAbvGr**: S·ªë ph√≤ng ng·ªß tr√™n t·∫ßng
* **GarageYrBlt**: NƒÉm ga ra ƒë∆∞·ª£c x√¢y d·ª±ng
* **LowQualFinSF**: Di·ªán t√≠ch ph·∫ßn ch·∫•t l∆∞·ª£ng th·∫•p nh·∫•t ƒë√£ ho√†n th√†nh
* **LotFrontage**: Di·ªán t√≠ch l√¥ ƒë·∫•t m·∫∑t ti·ªÅn
* **MasVnrArea**: Di·ªán t√≠ch g·∫°ch ·ªëp t∆∞·ªùng
* **WoodDeckSF**: Di·ªán t√≠ch s√†n g·ªó
* **OpenPorchSF**: Di·ªán t√≠ch hi√™n m·ªü
* **EnclosedPorch**: Di·ªán t√≠ch hi√™n nh√† k√≠n
* **3SsnPorch**: Di·ªán t√≠ch hi√™n nh√† ba m√πa
* **ScreenPorch**: Di·ªán t√≠ch hi√™n nh√† m·∫∑t ti·ªÅn
* **PoolArea**: Di·ªán t√≠ch h·ªì b∆°i
* **MiscVal**: Gi√° tr·ªã kh√°c
* **MoSold**: Month house was sold
* **YrSold**: NƒÉm b√°n nh√†
* **SalePrice**: Gi√° khuy·∫øn m√£i

## C√°ch s·ª≠ d·ª•ng

```bash
# clone the repo
git clone https://github.com/uzunb/house-prices-prediction-LGBM.git

# change to the repo directory
cd house-prices-prediction-LGBM

# if virtualenv is not installed, install it
#pip install virtualenv

# create a virtualenv
virtualenv -p python3 venv

# activate virtualenv for linux or mac
source venv/bin/activate

# activate virtualenv for windows
# venv\Scripts\activate

# install dependencies
pip install -r requirements.txt

# run the script
streamlit run main.py
```

## M√¥ h√¨nh ph√°t tri·ªÉn

### M√¥ h√¨nh
D·ª±a tr√™n thu·∫≠t to√°n [Grid Search Cross Validation](https://lightgbm.readthedocs.io/en/latest/index.html).

### Training

```python
import lightgbm as lgb

model = lgb.LGBMRegressor(max_depth=3, 
                    n_estimators = 100, 
                    learning_rate = 0.2,
                    min_child_samples = 10)
model.fit(x_train, y_train)
```

Grid Search Cross Validation is used for hyper parameters of the model.

```python
from sklearn.model_selection import GridSearchCV

params = [{"max_depth":[3, 5], 
            "n_estimators" : [50, 100], 
            "learning_rate" : [0.1, 0.2],
            "min_child_samples" : [20, 10]}]

gs_knn = GridSearchCV(model,
                      param_grid=params,
                      cv=5)

gs_knn.fit(x_train, y_train)
gs_knn.score(x_train, y_train)

pred_y_train = model.predict(x_train)
pred_y_test = model.predict(x_test)

r2_train = metrics.r2_score(y_train, pred_y_train)
r2_test = metrics.r2_score(y_test, pred_y_test)

msle_train =metrics.mean_squared_log_error(y_train, pred_y_train)
msle_test =metrics.mean_squared_log_error(y_test, pred_y_test)

print(f"Train r2 = {r2_train:.2f} \nTest r2 = {r2_test:.2f}")
print(f"Train msle = {msle_train:.2f} \nTest msle = {msle_test:.2f}")

print(gs_knn.best_params_)
```

### Evaluation

```python
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.metrics import explained_variance_score
from sklearn.metrics import mean_squared_log_error

y_pred = model.predict(x_test)
print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))
print('Mean Squared Log Error:', mean_squared_log_error(y_test, y_pred))
print('Explained Variance Score:', explained_variance_score(y_test, y_pred))
print('R2 Score:', r2_score(y_test, y_pred))
```

## Deployment

Simple model distribution is made using Streamlit.

```python
import streamlit as st

st.title("House Prices Prediction")
st.write("This is a simple model for house prices prediction.")

st.sidebar.title("Model Parameters")

variables = droppedDf["Alley"].drop_duplicates().to_list()
inputDict["Alley"] = st.sidebar.selectbox("Alley", options=variables)

inputDict["LotFrontage"] = st.sidebar.slider("LotFrontage", ceil(droppedDf["LotFrontage"].min()), 
floor(droppedDf["LotFrontage"].max()), int(droppedDf["LotFrontage"].mean()))
```


""")

app()